{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR--Media-Smart/vedastr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0Nmn5iiT3G9EipWhqjcfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nivratti/vedastr/blob/master/OCR_Media_Smart_vedastr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDBnTttxvucH"
      },
      "source": [
        "# Media-Smart/vedastr\n",
        "\n",
        "## Expectated Input:\n",
        "\n",
        "1) Input image: Must be only single word image.\n",
        "\n",
        "test image is located here:\n",
        "https://drive.google.com/drive/folders/1Zr17Rcc7gTJ9SPV5phN6TwE4jr6shP2w\n",
        "\n",
        "\n",
        "\n",
        "Input image will be resized to size 32, 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWCi2kM31QG9"
      },
      "source": [
        "## Clone code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp9b9mX3vqTj",
        "outputId": "b6501c20-64bd-43c9-eb45-1db14196d0bb"
      },
      "source": [
        "# !git clone https://github.com/Media-Smart/vedastr.git\n",
        "!git clone https://github.com/Nivratti/vedastr.git"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vedastr'...\n",
            "remote: Enumerating objects: 1573, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (167/167), done.\u001b[K\n",
            "remote: Total 1573 (delta 19), reused 96 (delta 5), pack-reused 1399\u001b[K\n",
            "Receiving objects: 100% (1573/1573), 358.14 KiB | 11.94 MiB/s, done.\n",
            "Resolving deltas: 100% (863/863), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfzfVj1PwuPA"
      },
      "source": [
        "## Move inside dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIIS9petwwEq",
        "outputId": "ae0c4e95-aa0b-4fb4-e898-49042c15e6e6"
      },
      "source": [
        "%cd \"/content/vedastr\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vedastr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZv1DpmGvtoE"
      },
      "source": [
        "## Download model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "FoAEIjG-vt2i",
        "outputId": "1e001444-6585-4655-e705-4c49da849dbc"
      },
      "source": [
        "import gdown\n",
        "\n",
        "# url = 'https://drive.google.com/uc?id=1YUOAU7xcrrsAtEqEGtI5ZD7eryP7Zr04'\n",
        "# output = 'tps_resnet_bilstm_attn.pth'\n",
        "# gdown.download(url, output, quiet=False)\n",
        "\n",
        "## Case sensitive model\n",
        "url = 'https://drive.google.com/uc?id=1bcKtEcYGIOehgPfGi_TqPkvrm6rjOUKR'\n",
        "output = 'small_satrn.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bcKtEcYGIOehgPfGi_TqPkvrm6rjOUKR\n",
            "To: /content/vedastr/small_satrn.pth\n",
            "195MB [00:03, 60.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'small_satrn.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGZPjLIfwToK"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "o1fQYOUswTzM",
        "outputId": "8327a31b-c861-4ebc-c3c9-8ad0ebd58e47"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.4.* in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 5)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.* in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 6)) (0.9.1+cu101)\n",
            "Collecting pillow<7.0,>=6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/3f/03375124676ab49ca6e6917c0f1f663afb8354d5d24e12f4fe4587a39ae2/Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 8)) (0.99)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 9)) (3.2.5)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (from -r vedastr/requirements.txt (line 11)) (0.1.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.*->-r vedastr/requirements.txt (line 5)) (3.7.4.3)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations->-r vedastr/requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (0.16.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r vedastr/requirements.txt (line 11)) (0.10.0)\n",
            "Building wheels for collected packages: terminaltables, imgaug\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=bbd07b0b17dc8dc5bd90796a1bacb4c8537cde0f7a27fbe41e721fc0f8fe6a8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=a7a60afde9d09ce33399322137af589fb6fe16d33821609b0f4ac1918d87e875\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built terminaltables imgaug\n",
            "\u001b[31mERROR: bokeh 2.3.1 has requirement pillow>=7.1.0, but you'll have pillow 6.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: addict, pillow, terminaltables, imgaug\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed addict-2.4.0 imgaug-0.2.6 pillow-6.2.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Q0dInII0JY"
      },
      "source": [
        "\n",
        "## Modify config file -- Enable support for case sensitive letters\n",
        "\n",
        "```python\n",
        "# test_sensitive = False # default\n",
        "test_sensitive = True\n",
        "# test_character = '0123456789abcdefghijklmnopqrstuvwxyz' # default\n",
        "test_character = '0123456789abcdefghijklmnopq' \\\n",
        "            'rstuvwxyzABCDEFGHIJKLMNOPQRS' \\\n",
        "            'TUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "8YQAbmmoI0Wp",
        "outputId": "d169e7f5-0016-41c6-e7aa-17d364e31eae"
      },
      "source": [
        "#@title Update config file\n",
        "\n",
        "%%writefile /content/vedastr/configs/small_satrn.py\n",
        "\n",
        "###############################################################################\n",
        "# 1. deploy\n",
        "\n",
        "size = (32, 100)\n",
        "mean, std = 0.5, 0.5\n",
        "\n",
        "sensitive = True\n",
        "character = '0123456789abcdefghijklmnopq' \\\n",
        "            'rstuvwxyzABCDEFGHIJKLMNOPQRS' \\\n",
        "            'TUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'  # need character\n",
        "\n",
        "# test_sensitive = False # default\n",
        "test_sensitive = True\n",
        "# test_character = '0123456789abcdefghijklmnopqrstuvwxyz' # default\n",
        "test_character = '0123456789abcdefghijklmnopq' \\\n",
        "            'rstuvwxyzABCDEFGHIJKLMNOPQRS' \\\n",
        "            'TUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "batch_max_length = 25\n",
        "\n",
        "dropout = 0.1\n",
        "n_e = 9\n",
        "n_d = 3\n",
        "hidden_dim = 256\n",
        "n_head = 8\n",
        "batch_norm = dict(type='BN')\n",
        "layer_norm = dict(type='LayerNorm', normalized_shape=hidden_dim)\n",
        "num_class = len(character) + 1\n",
        "num_steps = batch_max_length + 1\n",
        "\n",
        "deploy = dict(\n",
        "    gpu_id='0,1,2,3',\n",
        "    transform=[\n",
        "        dict(type='Sensitive', sensitive=sensitive, need_character=character),\n",
        "        dict(type='ToGray'),\n",
        "        dict(type='Resize', size=size),\n",
        "        dict(type='Normalize', mean=mean, std=std),\n",
        "        dict(type='ToTensor'),\n",
        "    ],\n",
        "    converter=dict(\n",
        "        type='AttnConverter',\n",
        "        character=character,\n",
        "        batch_max_length=batch_max_length,\n",
        "        go_last=True,\n",
        "    ),\n",
        "    model=dict(\n",
        "        type='GModel',\n",
        "        need_text=True,\n",
        "        body=dict(\n",
        "            type='GBody',\n",
        "            pipelines=[\n",
        "                dict(\n",
        "                    type='FeatureExtractorComponent',\n",
        "                    from_layer='input',\n",
        "                    to_layer='cnn_feat',\n",
        "                    arch=dict(\n",
        "                        encoder=dict(\n",
        "                            backbone=dict(\n",
        "                                type='GResNet',\n",
        "                                layers=[\n",
        "                                    ('conv',\n",
        "                                     dict(type='ConvModule', in_channels=1, out_channels=int(hidden_dim / 2),\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1, padding=1, norm_cfg=batch_norm)),\n",
        "                                    ('pool', dict(type='MaxPool2d', kernel_size=2, stride=2, padding=0)),\n",
        "                                    ('conv',\n",
        "                                     dict(type='ConvModule', in_channels=int(hidden_dim / 2), out_channels=hidden_dim,\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1, padding=1, norm_cfg=batch_norm)),\n",
        "                                    ('pool', dict(type='MaxPool2d', kernel_size=2, stride=2, padding=0)),\n",
        "                                ],\n",
        "                            ),\n",
        "                        ),\n",
        "                        collect=dict(type='CollectBlock', from_layer='c2'),\n",
        "                    ),\n",
        "                ),\n",
        "                dict(\n",
        "                    type='SequenceEncoderComponent',\n",
        "                    from_layer='cnn_feat',\n",
        "                    to_layer='src',\n",
        "                    arch=dict(\n",
        "                        type='TransformerEncoder',\n",
        "                        position_encoder=dict(\n",
        "                            type='Adaptive2DPositionEncoder',\n",
        "                            in_channels=hidden_dim,\n",
        "                            max_h=100,\n",
        "                            max_w=100,\n",
        "                            dropout=dropout,\n",
        "                        ),\n",
        "                        encoder_layer=dict(\n",
        "                            type='TransformerEncoderLayer2D',\n",
        "                            attention=dict(\n",
        "                                type='MultiHeadAttention',\n",
        "                                in_channels=hidden_dim,\n",
        "                                k_channels=hidden_dim // n_head,\n",
        "                                v_channels=hidden_dim // n_head,\n",
        "                                n_head=n_head,\n",
        "                                dropout=dropout,\n",
        "                            ),\n",
        "                            attention_norm=layer_norm,\n",
        "                            feedforward=dict(\n",
        "                                type='Feedforward',\n",
        "                                layers=[\n",
        "                                    dict(type='ConvModule', in_channels=hidden_dim, out_channels=hidden_dim * 4,\n",
        "                                         kernel_size=3, padding=1,\n",
        "                                         bias=True, norm_cfg=None, activation='relu', dropout=dropout),\n",
        "                                    dict(type='ConvModule', in_channels=hidden_dim * 4, out_channels=hidden_dim,\n",
        "                                         kernel_size=3, padding=1,\n",
        "                                         bias=True, norm_cfg=None, activation=None, dropout=dropout),\n",
        "                                ],\n",
        "                            ),\n",
        "                            feedforward_norm=layer_norm,\n",
        "                        ),\n",
        "                        num_layers=n_e,\n",
        "                    ),\n",
        "                ),\n",
        "            ],\n",
        "        ),\n",
        "        head=dict(\n",
        "            type='TransformerHead',\n",
        "            src_from='src',\n",
        "            num_steps=num_steps,\n",
        "            pad_id=num_class,\n",
        "            decoder=dict(\n",
        "                type='TransformerDecoder',\n",
        "                position_encoder=dict(\n",
        "                    type='PositionEncoder1D',\n",
        "                    in_channels=hidden_dim,\n",
        "                    max_len=100,\n",
        "                    dropout=dropout,\n",
        "                ),\n",
        "                decoder_layer=dict(\n",
        "                    type='TransformerDecoderLayer1D',\n",
        "                    self_attention=dict(\n",
        "                        type='MultiHeadAttention',\n",
        "                        in_channels=hidden_dim,\n",
        "                        k_channels=hidden_dim // n_head,\n",
        "                        v_channels=hidden_dim // n_head,\n",
        "                        n_head=n_head,\n",
        "                        dropout=dropout,\n",
        "                    ),\n",
        "                    self_attention_norm=layer_norm,\n",
        "                    attention=dict(\n",
        "                        type='MultiHeadAttention',\n",
        "                        in_channels=hidden_dim,\n",
        "                        k_channels=hidden_dim // n_head,\n",
        "                        v_channels=hidden_dim // n_head,\n",
        "                        n_head=n_head,\n",
        "                        dropout=dropout,\n",
        "                    ),\n",
        "                    attention_norm=layer_norm,\n",
        "                    feedforward=dict(\n",
        "                        type='Feedforward',\n",
        "                        layers=[\n",
        "                            dict(type='FCModule', in_channels=hidden_dim, out_channels=hidden_dim * 4, bias=True,\n",
        "                                 activation='relu', dropout=dropout),\n",
        "                            dict(type='FCModule', in_channels=hidden_dim * 4, out_channels=hidden_dim, bias=True,\n",
        "                                 activation=None, dropout=dropout),\n",
        "                        ],\n",
        "                    ),\n",
        "                    feedforward_norm=layer_norm,\n",
        "                ),\n",
        "                num_layers=n_d,\n",
        "            ),\n",
        "            generator=dict(\n",
        "                type='Linear',\n",
        "                in_features=hidden_dim,\n",
        "                out_features=num_class,\n",
        "            ),\n",
        "            embedding=dict(\n",
        "                type='Embedding',\n",
        "                num_embeddings=num_class + 1,\n",
        "                embedding_dim=hidden_dim,\n",
        "                padding_idx=num_class,\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    postprocess=dict(\n",
        "        sensitive=test_sensitive,\n",
        "        character=test_character,\n",
        "    ),\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 2.common\n",
        "\n",
        "common = dict(\n",
        "    seed=1111,\n",
        "    logger=dict(\n",
        "        handlers=(\n",
        "            dict(type='StreamHandler', level='INFO'),\n",
        "            dict(type='FileHandler', level='INFO'),\n",
        "        ),\n",
        "    ),\n",
        "    cudnn_deterministic=True,\n",
        "    cudnn_benchmark=True,\n",
        "    metric=dict(type='Accuracy'),\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "dataset_params = dict(\n",
        "    batch_max_length=batch_max_length,\n",
        "    data_filter=True,\n",
        "    character=character,\n",
        ")\n",
        "test_dataset_params = dict(\n",
        "    batch_max_length=batch_max_length,\n",
        "    data_filter=False,\n",
        "    character=test_character,\n",
        ")\n",
        "\n",
        "data_root = '../../../../dataset/str/data/data_lmdb_release/'\n",
        "\n",
        "###############################################################################\n",
        "# 3. test\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "# data\n",
        "test_root = data_root + 'evaluation/'\n",
        "test_folder_names = ['CUTE80', 'IC03_867', 'IC13_1015', 'IC15_2077',\n",
        "                     'IIIT5k_3000', 'SVT', 'SVTP']\n",
        "test_dataset = [dict(type='LmdbDataset', root=test_root + f_name,\n",
        "                     **test_dataset_params) for f_name in test_folder_names]\n",
        "\n",
        "test = dict(\n",
        "    data=dict(\n",
        "        dataloader=dict(\n",
        "            type='DataLoader',\n",
        "            batch_size=batch_size,\n",
        "            num_workers=4,\n",
        "            shuffle=False,\n",
        "        ),\n",
        "        dataset=test_dataset,\n",
        "        transform=[\n",
        "            dict(type='Sensitive', sensitive=test_sensitive, need_character=test_character),\n",
        "            dict(type='ToGray'),\n",
        "            dict(type='Resize', size=size),\n",
        "            dict(type='Normalize', mean=mean, std=std),\n",
        "            dict(type='ToTensor'),\n",
        "        ],\n",
        "    ),\n",
        "    postprocess_cfg=dict(\n",
        "        sensitive=test_sensitive,\n",
        "        character=test_character,\n",
        "    ),\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 4. train\n",
        "\n",
        "root_workdir = 'workdir'  # save directory\n",
        "\n",
        "# data\n",
        "train_root = data_root + 'training/'\n",
        "# MJ dataset\n",
        "train_root_mj = train_root + 'MJ/'\n",
        "mj_folder_names = ['/MJ_test', 'MJ_valid', 'MJ_train']\n",
        "# ST dataset\n",
        "train_root_st = train_root + 'ST/'\n",
        "\n",
        "train_dataset_mj = [dict(type='LmdbDataset', root=train_root_mj + folder_name)\n",
        "                    for folder_name in mj_folder_names]\n",
        "train_dataset_st = [dict(type='LmdbDataset', root=train_root_st)]\n",
        "\n",
        "# valid\n",
        "valid_root = data_root + 'validation/'\n",
        "valid_dataset = dict(type='LmdbDataset', root=valid_root, **test_dataset_params)\n",
        "\n",
        "train_transforms = [\n",
        "    dict(type='Sensitive', sensitive=sensitive, need_character=character),\n",
        "    dict(type='ToGray'),\n",
        "    dict(type='ExpandRotate', limit=34, p=0.5),\n",
        "    dict(type='Resize', size=size),\n",
        "    dict(type='Normalize', mean=mean, std=std),\n",
        "    dict(type='ToTensor'),\n",
        "]\n",
        "\n",
        "max_epochs = 6\n",
        "milestones = [2, 4]  # epoch start from 0, so 2 means lr decay at 3 epoch, 4 means lr decay at the end of\n",
        "\n",
        "train = dict(\n",
        "    data=dict(\n",
        "        train=dict(\n",
        "            dataloader=dict(\n",
        "                type='DataLoader',\n",
        "                batch_size=batch_size,\n",
        "                num_workers=4,\n",
        "            ),\n",
        "            sampler=dict(\n",
        "                type='BalanceSampler',\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                oversample=True,\n",
        "            ),\n",
        "            dataset=dict(\n",
        "                type='ConcatDatasets',\n",
        "                datasets=[\n",
        "                    dict(\n",
        "                        type='ConcatDatasets',\n",
        "                        datasets=train_dataset_mj,\n",
        "                    ),\n",
        "                    dict(\n",
        "                        type='ConcatDatasets',\n",
        "                        datasets=train_dataset_st,\n",
        "                    )\n",
        "                ],\n",
        "                batch_ratio=[0.5, 0.5],\n",
        "                **dataset_params,\n",
        "            ),\n",
        "            transform=train_transforms,\n",
        "        ),\n",
        "        val=dict(\n",
        "            dataloader=dict(\n",
        "                type='DataLoader',\n",
        "                batch_size=batch_size,\n",
        "                num_workers=4,\n",
        "                shuffle=False,\n",
        "            ),\n",
        "            dataset=valid_dataset,\n",
        "            transform=test['data']['transform'],\n",
        "        ),\n",
        "    ),\n",
        "    optimizer=dict(type='Adam', lr=3e-4),\n",
        "    criterion=dict(type='CrossEntropyLoss', ignore_index=num_class),\n",
        "    lr_scheduler=dict(type='CosineLR',\n",
        "                      iter_based=True,\n",
        "                      warmup_epochs=0.1,\n",
        "                      ),\n",
        "    max_epochs=max_epochs,\n",
        "    log_interval=10,\n",
        "    trainval_ratio=2000,\n",
        "    snapshot_interval=20000,\n",
        "    save_best=True,\n",
        "    resume=None,\n",
        ")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/vedastr/configs/small_satrn.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKf4NsnwiiU"
      },
      "source": [
        "## Inference on single word image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "628_0UnSJkzK",
        "outputId": "979e5fb7-67b9-412d-d796-a8d276ed1272"
      },
      "source": [
        "# download test image\n",
        "url = 'https://drive.google.com/uc?id=1TdFP9xNVofQxYuA_RK0FUiukHS0R2tZI'\n",
        "output = '/content/test.jpg'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TdFP9xNVofQxYuA_RK0FUiukHS0R2tZI\n",
            "To: /content/test.jpg\n",
            "100%|██████████| 14.3k/14.3k [00:00<00:00, 8.23MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/test.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE8Uh2r_wiu5",
        "outputId": "ecb91e72-e0af-41af-a580-48c82728a373"
      },
      "source": [
        "# # !python tools/inference.py configs/tps_resnet_bilstm_attn.py checkpoint_path img_path\n",
        "# !python tools/inference.py configs/tps_resnet_bilstm_attn.py \"/content/tps_resnet_bilstm_attn.pth\" \"/content/t.png\"\n",
        "\n",
        "!python tools/inference.py configs/small_satrn.py \"small_satrn.pth\" \"/content/test.jpg\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 05:43:39,086 - INFO - Use CPU\n",
            "2021-04-29 05:43:39,086 - INFO - Set cudnn deterministic True\n",
            "2021-04-29 05:43:39,086 - INFO - Set cudnn benchmark True\n",
            "2021-04-29 05:43:39,086 - INFO - Set seed 1111\n",
            "2021-04-29 05:43:39,087 - INFO - Build model\n",
            "2021-04-29 05:43:39,096 - INFO - GResNet init weights\n",
            "2021-04-29 05:43:39,505 - INFO - TransformerEncoder init weights\n",
            "2021-04-29 05:43:39,973 - INFO - TransformerDecoder init weights\n",
            "2021-04-29 05:43:40,007 - INFO - TransformerHead init weights\n",
            "2021-04-29 05:43:40,043 - INFO - Load checkpoint from small_satrn.pth\n",
            "2021-04-29 05:43:41,180 - INFO - predict string: ['RONALDO'] \t of /content/test.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
